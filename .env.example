# WhosMost Configuration
# Copy to .env and modify as needed

# --- Ollama / LLM ---
OLLAMA_URL=http://localhost:11434/api/generate
OLLAMA_MODEL=qwen2.5:14b-instruct
OLLAMA_TIMEOUT=120

# --- Cloud AI Providers (optional) ---
# Get a key at https://aistudio.google.com/apikey
GEMINI_API_KEY=
GEMINI_MODEL=gemini-2.0-flash
# Get a key at https://console.anthropic.com/
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929
# Default provider: ollama, gemini, or claude
DEFAULT_PROVIDER=ollama

# --- Server ---
HOST=0.0.0.0
PORT=8000
# Comma-separated origins, leave empty for auto-detect
ALLOWED_ORIGINS=

# --- Game ---
ROOM_TTL_SECONDS=1800

# --- Logging ---
# DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO
# Leave empty for stdout only, or set a file path
LOG_FILE=
